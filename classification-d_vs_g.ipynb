{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abline(slope, intercept, color='red'):\n",
    "    \"\"\"Plot a line from slope and intercept - adapted from https://stackoverflow.com/a/43811762\"\"\"\n",
    "    axes = plt.gca()\n",
    "    xrng = axes.get_xlim()\n",
    "    yrng = axes.get_xlim()\n",
    "    yrng2 = ((yrng[1]-intercept)/slope, (yrng[0]-intercept)/slope)\n",
    "    x_vals = [max(xrng[0], min(yrng2)), min(max(yrng2), xrng[1])]\n",
    "    x_vals = np.array(x_vals)\n",
    "    y_vals = intercept + slope * x_vals\n",
    "    plt.plot(x_vals, y_vals, '--', color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boundary(m):\n",
    "    \"\"\" extract and draw decision boundary from LogisticRegression \"\"\"\n",
    "    def _draw_boundary(coeffs, intercept, title=True):\n",
    "        a = -coeffs[0]/coeffs[1]\n",
    "        b = -intercept/coeffs[1]\n",
    "        abline(a,b, 'grey')\n",
    "        if title:\n",
    "            plt.title('Slope = {:.2f}'.format(a))    \n",
    "    _draw_boundary(m.coef_[0], m.intercept_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_2class_data(draw=True, lreg=True, fighandle=None):\n",
    "    data_class1 = np.random.randn(n,2)*sd + centers[0]\n",
    "    data_class2 = np.random.randn(n,2)*sd + centers[1]\n",
    "    data_all = np.concatenate((data_class1, data_class2), 0)\n",
    "\n",
    "    lbls = np.concatenate((np.zeros(200), np.ones(200))).astype(int)\n",
    "    lblcol = [cm.Set1.colors[l] for l in lbls]\n",
    "    if draw:\n",
    "        if fighandle is None:\n",
    "            fighandle = plt.figure()\n",
    "            fighandle.add_subplot(1,1,1)\n",
    "        ax = fighandle.axes[0]\n",
    "        ax.cla\n",
    "        ax.scatter(data_all[:,0], data_all[:,1], c=lblcol, alpha=0.7)\n",
    "    if lreg:\n",
    "        lmodel = LogisticRegression()\n",
    "        lmodel.fit(data_all, lbls)\n",
    "        draw_boundary(lmodel)\n",
    "        \n",
    "    return data_all, lbls, lblcol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminative Approach\n",
    "In this example we use logistic regression. We have not covered this yet in the ADS course, and we do not expect you to understand it at this stage - it is simply a linear boundary separating two classes. I hope it is nevertheless intuitive enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 200\n",
    "sd = 0.5\n",
    "centers = [np.array([1,0.5]), np.array([-1,-1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=plt.figure(figsize=(8,8))\n",
    "f.add_subplot(1,1,1)\n",
    "generate_2class_data(draw=True, lreg=True, fighandle=f);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Approach\n",
    "In this example we use an even more sophisticated algorithm -- which we will not cover in this course. The below is akin to Bayesian Logistic Regression. Understanding the concept demonstrated here is all I'm hoping to achieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, lblcols = generate_2class_data(draw=False, lreg=False, fighandle=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generative models also build a model of the input space too, i.e. a joint model of both the input variables and the target variables is built. They perform a kind of 'statistical inversion' which allows prediction of the targets given the inputs. This is extra effort, and more statistical strength can be used to model the target relationship if the distribution of the $x$'s is ignored. However, there are advantages of doing so:\n",
    "\n",
    "1. Missing values can be imputed as part of the model fitting procedure. NaN values are not a problem.\n",
    "2. Generative models provide a likelihood for test input data which can indicate how much similar data they have seen. This is a good proxy for uncertainty and anomaly.\n",
    "3. Synthetic data can be generated or 'hallucinated' from the model since they define a complete model from input space to output space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1,2)\n",
    "f.set_size_inches(14, 8)\n",
    "\n",
    "for i, ax, sl in zip(range(2), [ax1, ax2], [slice(0,200), slice(200,400)]):\n",
    "    ax = sns.kdeplot(x[sl,0],x[sl,1], bw=0.5, ax=ax)\n",
    "    ax.scatter(x[:,0],x[:,1],c=lblcols, alpha=0.7)\n",
    "    ax.set_title('Estimate of distribution class {:d}'.format(i))\n",
    "    ax.set_xlim([-3,3])\n",
    "    ax.set_ylim([-3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPy\n",
    "num_inducing = 200\n",
    "# Create GP model\n",
    "m = GPy.models.SparseGPClassification(x, y[:,None], num_inducing=num_inducing)\n",
    "m['.*len'] = 10.\n",
    "\n",
    "# Optimize\n",
    "m.optimize(messages=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create grid for heatmap\n",
    "n_grid = 500\n",
    "min_x      = np.array([-4,-4])\n",
    "max_x      = np.array([3,3])\n",
    "X1         = np.linspace(min_x[0],max_x[0],n_grid)\n",
    "X2         = np.linspace(min_x[1],max_x[1],n_grid)\n",
    "x1,x2      = np.meshgrid(X1,X2)\n",
    "Xgrid      = np.zeros([n_grid**2,2])\n",
    "Xgrid[:,0] = np.reshape(x1,(n_grid**2,))\n",
    "Xgrid[:,1] = np.reshape(x2,(n_grid**2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "probs = m.predict(Xgrid)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.contourf(X1,X2,np.reshape(probs,(n_grid,n_grid)),\n",
    "             levels = lev,cmap=cm.coolwarm)\n",
    "plt.plot(x[y==0,0],x[y==0,1],\"bo\", markersize = 3)\n",
    "plt.plot(x[y==1,0],x[y==1,1],\"ro\", markersize = 3)\n",
    "plt.colorbar()\n",
    "plt.title(\"Generative Classifier\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly import plotly\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "z_grid = np.concatenate((Xgrid, probs), 1)\n",
    "\n",
    "data = [\n",
    "    go.Surface(\n",
    "        x=X1, y=X2,\n",
    "        z=probs.reshape(n_grid, n_grid)\n",
    "    )\n",
    "]\n",
    "layout = go.Layout(\n",
    "    title='Generative Model',\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=800,\n",
    "    margin=dict(\n",
    "        l=65,\n",
    "        r=50,\n",
    "        b=65,\n",
    "        t=90\n",
    "    )\n",
    ")\n",
    "\n",
    "trace1 = go.Figure(data=data, layout=layout)\n",
    "iplot(trace1, layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (conda-torch)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
